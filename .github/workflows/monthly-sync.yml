name: Monthly Drug Inspection Sync

on:
  schedule:
    - cron: '0 0 1 * *'
  workflow_dispatch:

jobs:
  scrape-and-sync:
    runs-on: ubuntu-latest
    timeout-minutes: 360  # 6h max; we stop scraper at 5h to avoid being killed

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # Stop at 5h so we stay under 6h and can run sync + upload
      - name: Run scraper (max 5 hours)
        id: scrape
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          SCRAPER_CHECKPOINT_EVERY_ROWS: 2000
          SCRAPER_CHECKPOINT_DIR: ${{ github.workspace }}/artifacts/checkpoints
        run: |
          mkdir -p artifacts/checkpoints
          cd scripts
          timeout 300m python run_monthly_sync.py --all --table-name nexara_all_source --status-interval 25

      # Sync partial results when scraper hit time limit (exit 124) or failed
      - name: Sync partial results from checkpoints
        if: failure()
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          echo "Syncing partial results from checkpoints..."
          cd scripts
          python3 -c "
          import os, glob, csv, sys
          from pathlib import Path

          scripts_dir = Path('.').resolve()
          parent = scripts_dir.parent
          sys.path.insert(0, str(parent))
          sys.path.insert(0, str(scripts_dir))

          from run_monthly_sync import sync_new_records

          d = parent / 'artifacts' / 'checkpoints'
          files = list(d.glob('dpd_*.csv')) if d.exists() else []
          if not files:
              pat = os.path.join(parent, 'artifacts', 'checkpoints', 'dpd_*.csv')
              files = glob.glob(pat)
          if not files:
              print('No checkpoint files found')
              sys.exit(0)

          latest = max(files, key=lambda p: os.path.getmtime(str(p)))
          print('Loading from', latest)
          with open(str(latest), 'r', encoding='utf-8') as f:
              products = list(csv.DictReader(f))
          print('Loaded', len(products), 'products')

          if products:
              sync_new_records(
                  products,
                  os.getenv('SUPABASE_URL'),
                  os.getenv('SUPABASE_SERVICE_ROLE_KEY'),
                  'nexara_all_source',
                  batch_size=500,
              )
              print('Partial sync completed')
          "

      - name: Upload checkpoints and logs
        if: always()
        uses: actions/upload-artifact@v4
        continue-on-error: true
        with:
          name: checkpoints
          path: |
            artifacts/checkpoints/*.csv
            data/*.json
            data/*.xlsx
          retention-days: 30
          if-no-files-found: ignore
